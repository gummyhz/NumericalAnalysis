{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0kYpIvSIZlt"
      },
      "source": [
        "# Gauss-Seidel and Successive Over-Relaxation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mot8BEVU0-kI"
      },
      "source": [
        "In this notebook, you will explore the Gauss-Seidel method and its improvements with relaxation and iterative refinement.  That is, you will experiment with \"fine-tuning\".  Here, our parameters are:\n",
        "\n",
        "* initialized **x**\n",
        "* maximum number of iterations **max_iter**\n",
        "* relaxation parameter **$\\omega$**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54upjL2l13Cs"
      },
      "source": [
        "We will begin by initializing all variables needed later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GOvhnOT16YFQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "np.random.seed(123)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bERW8V2P6uBl"
      },
      "outputs": [],
      "source": [
        "A1 = np.array([[0.03, 58.9],[5.31, -6.10]])\n",
        "# A1 is not strictly diagonally dominant or symmetric positive definite\n",
        "A2 = np.array([[4, 3], [-1, 2]])\n",
        "A=A2\n",
        "b = np.array([[59.2],[47.0]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eou7dhGM64kX",
        "outputId": "4977fa6e-0145-48e0-df81-c6886f91ac17"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[4.4571847 ],\n",
              "       [5.49867272]])"
            ]
          },
          "execution_count": 108,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# choose something completely random since we don't usually know what the true value of x will be\n",
        "x0 = np.random.normal(loc = 5, scale = 0.5, size = (2,1))\n",
        "x0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahE9VqjDFhv9"
      },
      "source": [
        "We actually do have that the true solution is ${\\bf x} = (10,1)$, but we'll put this off to the side."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_0ECQOv_7FMD"
      },
      "outputs": [],
      "source": [
        "max_iter_GS = 5\n",
        "max_iter_SOR = 5\n",
        "ohm = 0.5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_mR1Kme53rq"
      },
      "source": [
        "In the code chunk below, we create a function for Gauss-Seidel.  Your **tasks**:\n",
        "\n",
        "1.   Comment the code and verify you understand it\n",
        "2.   Fill in any blanks based on Alg 7.2 (for Gauss-Seidel method)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rRKKPitt9U-i"
      },
      "outputs": [],
      "source": [
        "#G-S\n",
        "def GS(A, b, x0, max_iter):\n",
        "  '''\n",
        "  input: A, n-by-n matrix as numpy array, coefficient matrix for Ax = b\n",
        "  input: b, n-by-1 vector as numpy array, RHS to Ax = b\n",
        "  input: x, n-by-1 vector as numpy array, initialized vector\n",
        "  input: max_iter, an int, the max number of iterations user desires\n",
        "\n",
        "  output: x, n-by-1 vector, solution to Ax = b after max_iter iterations\n",
        "  '''\n",
        "  x = x0.copy()\n",
        "  for k in range(max_iter):\n",
        "\n",
        "    n, m = A.shape\n",
        "    x_last = x.copy()\n",
        "\n",
        "    for i in range(m):\n",
        "      sum_term = 0;\n",
        "      for j in range(m):\n",
        "        if j < i:\n",
        "          sum_term += A[i,j]*x[j];\n",
        "        elif j > i:\n",
        "          sum_term += A[i,j]*x_last[j];\n",
        "\n",
        "      sum_term = (b[i]) - sum_term; #fill in blank\n",
        "      x[i] = (1/A[i,i])*sum_term; #fill in blank\n",
        "\n",
        "    error = np.linalg.norm(x - x_last, 2)\n",
        "\n",
        "  return x, error\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrDt_Pt56cHw"
      },
      "source": [
        "Similarly, in the code chunk below, we create a function for Gauss-Seidel with Relaxation, called Successive Over-Relaxation.  Your **tasks**:\n",
        "\n",
        "1.   Comment the code and verify you understand it\n",
        "2.   Fill in any blanks based on Alg 7.3 (for SOR method)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eyxRfUUT7Qlf"
      },
      "outputs": [],
      "source": [
        "# SOR\n",
        "def SOR(A, b, x0, max_iter, omega):\n",
        "  '''\n",
        "  input: A, n-by-n matrix as numpy array, coefficient matrix for Ax = b\n",
        "  input: b, n-by-1 vector as numpy array, RHS to Ax = b\n",
        "  input: x, n-by-1 vector as numpy array, initialized vector\n",
        "  input: max_iter, an int, the max number of iterations user desires\n",
        "  input: omega, a decimal between 0 and 2, the relaxation coefficient\n",
        "\n",
        "  output: x, n-by-1 vector, solution to Ax = b after max_iter iterations\n",
        "  '''\n",
        "  x = x0.copy()\n",
        "\n",
        "\n",
        "  for k in range(max_iter):\n",
        "\n",
        "    n, m = A.shape\n",
        "    x_last = x.copy()\n",
        "\n",
        "\n",
        "    for i in range(m):\n",
        "\n",
        "      term1 = (1-omega)*x_last[i]; # fill in blank\n",
        "\n",
        "      sum_term = 0;\n",
        "      for j in range(m):\n",
        "        if j < i:\n",
        "          sum_term += A[i,j]*x[j];\n",
        "        elif j > i:\n",
        "          sum_term += A[i,j]*x_last[j];\n",
        "          # could replace this j loop with np.dot....\n",
        "\n",
        "\n",
        "      sum_term = b[i] - sum_term;\n",
        "      term2 = (1/A[i,i])*omega*sum_term; #fill in blank\n",
        "      x[i] = term1 + term2;\n",
        "\n",
        "    error = np.linalg.norm(x - x_last, 2)\n",
        "\n",
        "  return x, error\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5TRAmyu676y"
      },
      "source": [
        "Now we'll compare the two methods.  The code chunks below should run with no error if you filled in the blanks correctly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nBEepDe63Z3V",
        "outputId": "dbeed844-0f07-470a-8a4f-cf108decdd79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "the residual under 2-norm is  0.021659882213460969480056661496\n",
            "the error between last two iterations under 2-norm is 0.036795919717867477116701735440\n"
          ]
        }
      ],
      "source": [
        "\n",
        "x, error = GS(A, b, x0, max_iter_GS)\n",
        "residual_norm = np.linalg.norm(b - A@x, 2)\n",
        "\n",
        "print(\"the residual under 2-norm is \", f\"{residual_norm:.30f}\")\n",
        "print(\"the error between last two iterations under 2-norm is\", f\"{error:.30f}\") # change error so it prints same num o digits as residual norm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDtvvXqh0SwA",
        "outputId": "f872cf4e-ff58-4d96-b317-4ae93ecb6d31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "the residual under 2-norm is  0.489129791777300038102538337625\n",
            "the error between last two iterations under 2-norm is 0.159916305927011309639951264217\n"
          ]
        }
      ],
      "source": [
        "x, error = SOR(A, b, x0, max_iter_SOR, ohm)\n",
        "residual_norm = np.linalg.norm(b - A@x, 2)\n",
        "\n",
        "print(\"the residual under 2-norm is \", f\"{residual_norm:.30f}\")\n",
        "print(\"the error between last two iterations under 2-norm is\", f\"{error:.30f}\") # change error so it prints same num o digits as residual norm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppNVu5jeJAW1"
      },
      "source": [
        "### Task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3nWVPyZ4VqM"
      },
      "source": [
        "Given the results you see, modify the number of iterations or the $\\omega$ and see if you can achieve even better results!   We may be able to get those residual norms even smaller!\n",
        "\n",
        "Either with Gauss-Seidel or Successive Over-Relaxation.\n",
        "\n",
        "You should make a table that keeps track of the changes. You may use the table below: fill it in by double clicking on this text, and then filling in the empty spots.\n",
        "\n",
        "\n",
        "In a new text box below, state what elements were kept the same.  For example, the initialized **x** vector you used should stay the same in order for the best comparison between methods.  Place name next to response.  For example,\n",
        "\n",
        "Amanda: here is my response.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLq8B_440utC"
      },
      "source": [
        "Rebecca:\n",
        "```\n",
        "np.random.seed(123)\n",
        "A = np.array([[4, 3], [-1, 2]])\n",
        "b = np.array([[59.2],[47.0]])\n",
        "x = array([[4.4571847 ],[5.49867272]])\n",
        "ohm = 0.9\n",
        "I varied max_iter: 1,2,3,4,5\n",
        "```\n",
        "GS\n",
        "| # iterations | omega | residual norm | convergence norm |\n",
        "|---|---|---|---|\n",
        "| 1  | 0.2  | 70.017975016421374334640859160572  | 24.153627035491886942963901674375  |\n",
        "| 2  | 0.2  | 26.256740631158017151847161585465  | 19.570618972950015290734882000834  |\n",
        "| 3  | 0.2  | 9.846277736684257320121105294675  | 7.338982114856257510382420150563  |\n",
        "| 4  | 0.2  | 3.692354151256580507833859883249  | 2.752118293071094345947358306148  |\n",
        "| 5  | 0.2  |  1.384632806721199926869303453714  | 1.032044359901655328215497320343  |\n",
        "\n",
        "\n",
        "SOR\n",
        "| # iterations | omega | residual norm | convergence norm |\n",
        "|---|---|---|---|\n",
        "| 1  | 0.2  | 59.866539577100041924495599232614  | 21.467973349577476938065956346691  |\n",
        "| 2  | 0.2  | 6.009138869072915056790407106746  | 14.004815142586437559657497331500  |\n",
        "| 3  | 0.2  | 0.049617159942428670782454958044  |  1.352978200825121213313195767114 |\n",
        "| 4  | 0.2  |  0.057532447537066766507507509232  | 0.018998307332290794574580772291  |\n",
        "| 5  | 0.2  | 0.006214497026969463371048885136  | 0.013506445809779159261676539927  |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXKgShZczqKE"
      },
      "source": [
        "Rose:\n",
        "```\n",
        "np.random.seed(123)\n",
        "A = np.array([[4, 3], [-1, 2]])\n",
        "b = np.array([[59.2],[47.0]])\n",
        "x = array([[4.4571847 ],[5.49867272]])\n",
        "ohm = 0.5\n",
        "I varied max_iter: 1,2,3,4,5\n",
        "```\n",
        "GS\n",
        "| # iterations | omega | residual norm | convergence norm |\n",
        "|---|---|---|---|\n",
        "| 1  | 0.2  | 8.611141421031337728209109627642  | 9.318647163214171413869735260960  |\n",
        "| 2  | 0.2  | 2.292722710532937302474465468549  | 2.248255897427581029290877268068  |\n",
        "| 3  | 0.2  | 0.408886724570231729902758388562  | 0.807158557557196232323803997133  |\n",
        "| 4  | 0.2  | 0.113229227781592597934512411939  | 0.084006565402534788544741672922  |\n",
        "| 5  | 0.2  |  0.021659882213460969480056661496  | 0.036795919717867477116701735440  |\n",
        "\n",
        "\n",
        "SOR\n",
        "| # iterations | omega | residual norm | convergence norm |\n",
        "|---|---|---|---|\n",
        "| 1  | 0.2  | 29.733472480009904614917104481719  | 5.597785569069185562796064914437  |\n",
        "| 2  | 0.2  | 9.905224442797720740827571717091  | 2.030000105667451926194644329371  |\n",
        "| 3  | 0.2  | 3.149562165606044406018781955936  |  0.777965953959595335476251420914 |\n",
        "| 4  | 0.2  |  1.063625818560870683882058074232  | 0.334695594399201434843149627341  |\n",
        "| 5  | 0.2  | 0.489129791777300038102538337625  | 0.013506445809779159261676539927  |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9MTvcsAIkRS"
      },
      "source": [
        "## Iterative Refinement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5PoA3qXF0bC"
      },
      "source": [
        "In the portion below, we'll implement iterative refinement.  The text applies it after Gaussian elimination, since G.E. with $k$-digit rounding/chopping will give an approximation to the true solution.\n",
        "\n",
        "However, we can apply iterative refinement to any method that attempts to solve $A{\\bf x} = {\\bf b}$ through approximation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKRcYLrkGKJZ"
      },
      "source": [
        "Let's see what impact it might have on Gauss-Seidel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y_j-iMnd8KOr"
      },
      "outputs": [],
      "source": [
        "# Iterative Refinement\n",
        "\n",
        "x, error = GS(A, b, x0, max_iter_GS)\n",
        "r = b - A@x\n",
        "y = np.linalg.solve(A,r)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJFsafUQzyhm",
        "outputId": "9a09da25-475f-4a13-c3cd-881c31d29019"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[-12.73054091],\n",
              "       [ -6.36527046]])"
            ]
          },
          "execution_count": 115,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SH4TvP4z0Gu",
        "outputId": "7cf9edba-ae31-4790-85a5-3ce95ea47d7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "new error is  14.23317743487274 old error is  24.153627035491887\n"
          ]
        }
      ],
      "source": [
        "new_x = y + x\n",
        "print(\"new error is \", np.linalg.norm(x - new_x, 2), \"old error is \", error)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZH4p9J4Izb1"
      },
      "source": [
        "### Task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJ3LyqsSFEEj"
      },
      "source": [
        "Did it do better than plain Gauss-Seidel?  Or, does it not make much of a difference here?  What about compared to SOR method?  Put your answers in this text box.  Please put your name next to that response.\n",
        "\n",
        "Rebecca: This round of iterative refinement after GS improved the results quite a bit - here with 5 iterations, new error is  0.2814666436095386 old error is  1.0320443599016553. This is better than SOR method with an error between last two iterations under 2-norm of 0.013506445809779159261676539927."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-qrC20uI2jv"
      },
      "source": [
        "### Task\n",
        "Create a while loop here that'll keep doing the refinement until $||y||_2 \\leq 10^{-t}$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pU1FYRy3E5ck"
      },
      "outputs": [],
      "source": [
        "def refine(x_in):\n",
        "  x = x_in.copy()\n",
        "  TOL=1e-3\n",
        "  i = 0\n",
        "  while (True):\n",
        "    i += 1\n",
        "    r = b - A@x\n",
        "    y = np.linalg.solve(A,r)\n",
        "    new_x = y + x\n",
        "    error = np.linalg.norm(x - new_x, 2)\n",
        "    if (error < TOL):\n",
        "      print(f\"Error below tolerance - stopping refinement at {i} iterations\")\n",
        "      break\n",
        "    x = new_x # this is fine to not do .copy() because new_x = x + y assigns a new array object to new_x; skipping copy to safe some time and memory\n",
        "  return new_x, error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLJIfduR8yz3",
        "outputId": "a25e7abd-1882-425c-a0d5-67bb5d86ce27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error below tolerance - stopping refinement at 2 iterations\n",
            "new error is  1.3322676295501878e-15 old error is  24.153627035491887\n"
          ]
        }
      ],
      "source": [
        "x, error = GS(A, b, x0, max_iter_GS)\n",
        "new_x, new_error = refine(x)\n",
        "print(\"new error is \", new_error, \"old error is \", error)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxf7HaSbIqtf"
      },
      "source": [
        "# Task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yk9MSyR-HUw2"
      },
      "source": [
        "Explore G-S, SOR, and iterative refinement methods to find a solution to the augmented system\n",
        "\n",
        "$$\n",
        "\\left[\n",
        "\\begin{array}{ccc|c}\n",
        "3 & -1 & 1 & 1\\\\\n",
        "3 & 6 & 2 & 0\\\\\n",
        "3 & 3 & 7 & 4\n",
        "\\end{array}\n",
        "\\right].\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O3zW-b9QFUTr",
        "outputId": "61b08693-6bca-4b8c-9c04-3a632c096ade"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error below tolerance - stopping refinement at 2 iterations\n",
            "GS: new error is 2.0816681711721685e-16 old error is 9.318647163214171\n",
            "\n",
            "Error below tolerance - stopping refinement at 2 iterations\n",
            "SOR: new error is 5.497075661425421e-16 old error is 5.597785569069186\n",
            "\n"
          ]
        }
      ],
      "source": [
        "np.random.seed(123)\n",
        "x0 = np.random.normal(loc = 5, scale = 0.5, size = (3,1))\n",
        "A = np.array([[3,-1,1],\n",
        "              [3,6,2],\n",
        "              [3,3,7]])\n",
        "b = np.array([[1],[0],[4]])\n",
        "\n",
        "x, error = GS(A, b, x0, max_iter_GS)\n",
        "new_x, new_error = refine(x)\n",
        "print(f\"GS: new error is {new_error} old error is {error}\\n\")\n",
        "\n",
        "x, error = SOR(A, b, x0, max_iter_GS, ohm)\n",
        "new_x, new_error = refine(x)\n",
        "print(f\"SOR: new error is {new_error} old error is {error}\\n\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
